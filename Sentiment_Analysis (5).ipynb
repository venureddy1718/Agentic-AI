{
  "cells": [
    {
      "source": [
        "!pip install duckduckgo_search\n",
        "from duckduckgo_search import DDGS # Import DDGS\n",
        "\n",
        "def fetch_news_duckduckgo(query, max_results=5):\n",
        "    headlines = []\n",
        "    with DDGS() as ddgs:\n",
        "        for r in ddgs.news(query, max_results=max_results):\n",
        "            headlines.append(r['title'])\n",
        "    return headlines # This line was incorrectly indented\n",
        "\n",
        "# Remove the duplicated code block:\n",
        "# for r in ddgs.news(query, max_results=max_results):\n",
        "#     headlines.append(r['title'])\n",
        "# return headlines\n",
        "\n",
        "fetch_news_duckduckgo('apple shares')"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wbe3W4H9sVqX",
        "outputId": "d50716ee-6e3a-48a5-ba1b-af93d101f376"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: duckduckgo_search in /usr/local/lib/python3.11/dist-packages (8.0.1)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo_search) (8.1.8)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo_search) (0.15.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo_search) (5.4.0)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Apple shares slump as tariffs take toll on iPhone maker',\n",
              " 'Apple shares fall as tariff costs to add more agony',\n",
              " \"Apple's first bond offering in two years headlines busy primary\",\n",
              " 'Apple (AAPL) adds $100 billion to its share buyback program and ups dividend payout again',\n",
              " 'Warren Buffett hails Tim Cook for making Berkshire more money than he has — after selling two-thirds of his Apple stake']"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEXW6NObMrjv",
        "outputId": "6535f830-58b9-452d-9322-1dafb46b3939"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: duckduckgo_search in /usr/local/lib/python3.11/dist-packages (8.0.1)\n",
            "Requirement already satisfied: click>=8.1.8 in /usr/local/lib/python3.11/dist-packages (from duckduckgo_search) (8.1.8)\n",
            "Requirement already satisfied: primp>=0.15.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo_search) (0.15.0)\n",
            "Requirement already satisfied: lxml>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from duckduckgo_search) (5.4.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install duckduckgo_search\n",
        "from duckduckgo_search import DDGS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gRMTccONoyTK",
        "outputId": "0d5706d6-0a75-4944-bfc9-3efe380f6ed3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: feedparser in /usr/local/lib/python3.11/dist-packages (6.0.11)\n",
            "Requirement already satisfied: sgmllib3k in /usr/local/lib/python3.11/dist-packages (from feedparser) (1.0.0)\n"
          ]
        }
      ],
      "source": [
        "pip install feedparser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "c1ySQUS8lCXf"
      },
      "outputs": [],
      "source": [
        "import feedparser\n",
        "\n",
        "def get_google_news_rss(company):\n",
        "    feed_url = f\"https://news.google.com/rss/search?q={company}+stock\"\n",
        "    feed = feedparser.parse(feed_url)\n",
        "    return [entry['title'] for entry in feed.entries[:10]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQ8uNjQTpKHe",
        "outputId": "dd04e5e7-7351-4a98-e73c-3067897f9658"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        }
      ],
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "S5tEZLW9trZv",
        "outputId": "2076fbb2-1415-4c7a-e8ad-81e744e3e4c1"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'd1' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-a8d54886425b>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mticker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheadlines\u001b[0m \u001b[0;32min\u001b[0m \u001b[0md1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mheadline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mheadlines\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheadline\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Pass individual headline to the pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;31m# Check if result is a list and convert to dictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'd1' is not defined"
          ]
        }
      ],
      "source": [
        "results = []\n",
        "for ticker, headlines in d1.items():\n",
        "    for headline in headlines:\n",
        "        result = pipe(headline)  # Pass individual headline to the pipeline\n",
        "        # Check if result is a list and convert to dictionary\n",
        "        if isinstance(result, list):\n",
        "            result = result[0]  # Assuming the first element is the relevant dictionary\n",
        "        results.append({\"ticker\": ticker, \"headline\": headline, **result})  # Store ticker, headline, and result\n",
        "\n",
        "# Aggregate sentiment\n",
        "sentiment_counts = {\"positive\": 0, \"neutral\": 0, \"negative\": 0}\n",
        "for result in results:\n",
        "    label = result[\"label\"].lower()\n",
        "    sentiment_counts[label] += 1\n",
        "    print(f\"{result['ticker']} - {result['headline']}\\n   ➤ Sentiment: {result['label']} (Confidence: {round(result['score'], 3)})\\n\")\n",
        "\n",
        "# Show overall sentiment\n",
        "total = sum(sentiment_counts.values())\n",
        "print(\"=== Overall Apple Sentiment Summary ===\")  # Assuming you want sentiment for AAPL\n",
        "for sentiment, count in sentiment_counts.items():\n",
        "    print(f\"{sentiment.capitalize()}: {count} ({round(count / total * 100, 1)}%)\")\n",
        "\n",
        "overall = max(sentiment_counts, key=sentiment_counts.get)\n",
        "print(f\"\\n📊 Overall Market Sentiment on {ticker}: **{overall.upper()}**\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ijknw-EFvP0z",
        "outputId": "48468126-b2ff-454f-a5b6-f78d102a0792"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--- Sentiment Analysis for AAPL ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for MSFT ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for GOOGL ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for AMZN ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for TSLA ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for META ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for NVDA ---\n",
            "Positive: 0\n",
            "Neutral: 1\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for BRK-B ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for JPM ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for V ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for PG ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for JNJ ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for UNH ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for HD ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for MA ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for DIS ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for PYPL ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for NFLX ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for INTC ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n",
            "--- Sentiment Analysis for PEP ---\n",
            "Positive: 0\n",
            "Neutral: 10\n",
            "Negative: 0\n",
            "Overall Sentiment: NEUTRAL\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import yfinance as yf\n",
        "\n",
        "# Load FinBERT sentiment analysis pipeline\n",
        "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
        "\n",
        "def fetch_company_news(tickers):\n",
        "    \"\"\"\n",
        "    Fetches the latest news headlines for a list of companies.\n",
        "\n",
        "    Args:\n",
        "    tickers (list): List of stock ticker symbols (e.g., ['AAPL', 'TSLA', 'AMZN']).\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where the keys are ticker symbols and the values are lists of news headlines.\n",
        "    \"\"\"\n",
        "    news_dict = {}\n",
        "\n",
        "    for ticker_symbol in tickers:\n",
        "        ticker = yf.Ticker(ticker_symbol)\n",
        "        news_data = ticker.news\n",
        "\n",
        "        if news_data:\n",
        "            headlines = [article.get(\"title\", \"\") for article in news_data]\n",
        "            news_dict[ticker_symbol] = headlines\n",
        "        else:\n",
        "            news_dict[ticker_symbol] = [\"No recent news found.\"]\n",
        "\n",
        "    return news_dict\n",
        "\n",
        "def analyze_sentiment_for_all_companies(tickers):\n",
        "    \"\"\"\n",
        "    Analyzes sentiment for the news of multiple companies and returns an overall sentiment for each company.\n",
        "\n",
        "    Args:\n",
        "    tickers (list): List of stock ticker symbols (e.g., ['AAPL', 'TSLA', 'AMZN']).\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary where the keys are ticker symbols and the values are the overall sentiment ('positive', 'neutral', 'negative').\n",
        "    \"\"\"\n",
        "    news_dict = fetch_company_news(tickers)\n",
        "\n",
        "    sentiment_results = {}\n",
        "\n",
        "    for ticker, headlines in news_dict.items():\n",
        "        sentiment_counts = {\"positive\": 0, \"neutral\": 0, \"negative\": 0}\n",
        "\n",
        "        # Analyze sentiment for each headline\n",
        "        results = pipe(headlines)\n",
        "\n",
        "        for result in results:\n",
        "            label = result[\"label\"].lower()\n",
        "            sentiment_counts[label] += 1\n",
        "\n",
        "        # Determine overall sentiment\n",
        "        total = sum(sentiment_counts.values())\n",
        "        overall_sentiment = max(sentiment_counts, key=sentiment_counts.get)\n",
        "\n",
        "        sentiment_results[ticker] = {\n",
        "            \"positive\": sentiment_counts[\"positive\"],\n",
        "            \"neutral\": sentiment_counts[\"neutral\"],\n",
        "            \"negative\": sentiment_counts[\"negative\"],\n",
        "            \"overall_sentiment\": overall_sentiment.upper()\n",
        "        }\n",
        "\n",
        "    return sentiment_results\n",
        "\n",
        "# List of tickers to analyze\n",
        "ticker_list = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"META\", \"NVDA\", \"BRK-B\", \"JPM\", \"V\",\n",
        "    \"PG\", \"JNJ\", \"UNH\", \"HD\", \"MA\", \"DIS\", \"PYPL\", \"NFLX\", \"INTC\", \"PEP\"\n",
        "]\n",
        "\n",
        "# Perform sentiment analysis for all companies in the ticker list\n",
        "sentiment_analysis = analyze_sentiment_for_all_companies(ticker_list)\n",
        "\n",
        "# Print the overall sentiment for each company\n",
        "for ticker, sentiment_data in sentiment_analysis.items():\n",
        "    print(f\"--- Sentiment Analysis for {ticker} ---\")\n",
        "    print(f\"Positive: {sentiment_data['positive']}\")\n",
        "    print(f\"Neutral: {sentiment_data['neutral']}\")\n",
        "    print(f\"Negative: {sentiment_data['negative']}\")\n",
        "    print(f\"Overall Sentiment: {sentiment_data['overall_sentiment']}\")\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JWfUq2sx3ZAb",
        "outputId": "aa696e4d-763a-46c9-e1b5-08500ed9d54e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.11/dist-packages (5.29.0)\n",
            "Requirement already satisfied: aiofiles<25.0,>=22.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (24.1.0)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.9.0)\n",
            "Requirement already satisfied: fastapi<1.0,>=0.115.2 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.115.12)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.11/dist-packages (from gradio) (0.5.0)\n",
            "Requirement already satisfied: gradio-client==1.10.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (1.10.0)\n",
            "Requirement already satisfied: groovy~=0.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.2)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.28.1)\n",
            "Requirement already satisfied: huggingface-hub>=0.28.1 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.30.2)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.1.6)\n",
            "Requirement already satisfied: markupsafe<4.0,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.0.2)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.0.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (3.10.18)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from gradio) (24.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.2.2)\n",
            "Requirement already satisfied: pillow<12.0,>=8.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (11.2.1)\n",
            "Requirement already satisfied: pydantic<2.12,>=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.11.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.11/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.18 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.0.20)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (6.0.2)\n",
            "Requirement already satisfied: ruff>=0.9.3 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.11.8)\n",
            "Requirement already satisfied: safehttpx<0.2.0,>=0.1.6 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.1.6)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: starlette<1.0,>=0.40.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.46.2)\n",
            "Requirement already satisfied: tomlkit<0.14.0,>=0.12.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.13.2)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.15.3)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (4.13.2)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.11/dist-packages (from gradio) (0.34.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (2025.3.2)\n",
            "Requirement already satisfied: websockets<16.0,>=10.0 in /usr/local/lib/python3.11/dist-packages (from gradio-client==1.10.0->gradio) (15.0.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (3.10)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx>=0.24.1->gradio) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.16.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (3.18.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.28.1->gradio) (4.67.1)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0,>=1.0->gradio) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<2.12,>=2.0->gradio) (0.4.0)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.8)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.11/dist-packages (from typer<1.0,>=0.12->gradio) (13.9.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.11/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.19.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.28.1->gradio) (2.4.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.11/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n"
          ]
        }
      ],
      "source": [
        "pip install gradio\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "ZUg6fv5n9WZ-",
        "outputId": "b280f1d9-d14f-4c0e-8805-ae2814148043"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b1bf632a37e9ba42f7.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b1bf632a37e9ba42f7.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 34
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import yfinance as yf\n",
        "import gradio as gr\n",
        "\n",
        "# Load FinBERT pipeline\n",
        "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
        "\n",
        "# Global headlines store\n",
        "all_headlines = {}\n",
        "\n",
        "# Ticker list\n",
        "ticker_list = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"META\", \"NVDA\", \"BRK-B\", \"JPM\", \"V\",\n",
        "    \"PG\", \"JNJ\", \"UNH\", \"HD\", \"MA\", \"DIS\", \"PYPL\", \"NFLX\", \"INTC\", \"PEP\"\n",
        "]\n",
        "\n",
        "def fetch_company_news(tickers):\n",
        "    global all_headlines\n",
        "    news_dict = {}\n",
        "\n",
        "    for ticker_symbol in tickers:\n",
        "        ticker = yf.Ticker(ticker_symbol)\n",
        "        news_data = ticker.news\n",
        "\n",
        "        if news_data:\n",
        "            headlines = [article.get(\"title\", \"\") for article in news_data]\n",
        "        else:\n",
        "            headlines = [\"No recent news found.\"]\n",
        "\n",
        "        news_dict[ticker_symbol] = headlines\n",
        "\n",
        "    all_headlines = news_dict\n",
        "    return news_dict\n",
        "\n",
        "def analyze_single_ticker_sentiment(ticker_symbol):\n",
        "    if ticker_symbol not in all_headlines:\n",
        "        fetch_company_news([ticker_symbol])\n",
        "\n",
        "    headlines = all_headlines.get(ticker_symbol, [\"No recent news found.\"])\n",
        "\n",
        "    if headlines == [\"No recent news found.\"]:\n",
        "        return \"No recent news available.\", \"\"\n",
        "\n",
        "    sentiment_counts = {\"positive\": 0, \"neutral\": 0, \"negative\": 0}\n",
        "    results = pipe(headlines)\n",
        "\n",
        "    output_lines = []\n",
        "    for i, (headline, result) in enumerate(zip(headlines, results), 1):\n",
        "        label = result[\"label\"].lower()\n",
        "        sentiment_counts[label] += 1\n",
        "        output_lines.append(f\"{i}. {headline}\\n   ➤ Sentiment: {result['label']} (Confidence: {round(result['score'], 3)})\")\n",
        "\n",
        "    total = sum(sentiment_counts.values())\n",
        "    overall = max(sentiment_counts, key=sentiment_counts.get)\n",
        "\n",
        "    summary = f\"📊 Overall Sentiment for {ticker_symbol}: {overall.upper()}\\n\"\n",
        "    summary += f\"Positive: {sentiment_counts['positive']}  |  Neutral: {sentiment_counts['neutral']}  |  Negative: {sentiment_counts['negative']}\"\n",
        "\n",
        "    return \"\\n\\n\".join(output_lines), summary\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# 📰 Stock News Sentiment Analysis with FinBERT\")\n",
        "\n",
        "    with gr.Row():\n",
        "        ticker_input = gr.Dropdown(choices=ticker_list, label=\"Select a Stock Ticker\")\n",
        "        analyze_button = gr.Button(\"Analyze\")\n",
        "\n",
        "    sentiment_output = gr.Textbox(label=\"News Headlines & Sentiments\", lines=15)\n",
        "    summary_output = gr.Textbox(label=\"Overall Sentiment Summary\")\n",
        "\n",
        "    analyze_button.click(\n",
        "        fn=analyze_single_ticker_sentiment,\n",
        "        inputs=[ticker_input],\n",
        "        outputs=[sentiment_output, summary_output]\n",
        "    )\n",
        "\n",
        "# Launch the app\n",
        "app.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "LJ93yLgn-p39",
        "outputId": "5708aca0-6727-46f3-f5f4-2cc773dc7a6b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://bfcb7dce70581f3b7a.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://bfcb7dce70581f3b7a.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "import yfinance as yf\n",
        "import gradio as gr\n",
        "\n",
        "# Load FinBERT pipeline\n",
        "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
        "\n",
        "# Global headlines store\n",
        "all_headlines = {}\n",
        "\n",
        "# Ticker list\n",
        "ticker_list = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"META\", \"NVDA\", \"BRK-B\", \"JPM\", \"V\",\n",
        "    \"PG\", \"JNJ\", \"UNH\", \"HD\", \"MA\", \"DIS\", \"PYPL\", \"NFLX\", \"INTC\", \"PEP\"\n",
        "]\n",
        "\n",
        "def fetch_company_news(tickers):\n",
        "    global all_headlines\n",
        "    news_dict = {}\n",
        "\n",
        "    for ticker_symbol in tickers:\n",
        "        ticker = yf.Ticker(ticker_symbol)\n",
        "        news_data = ticker.news\n",
        "\n",
        "        if news_data:\n",
        "            headlines = [article.get(\"title\", \"\") for article in news_data]\n",
        "        else:\n",
        "            headlines = [\"No recent news found.\"]\n",
        "\n",
        "        news_dict[ticker_symbol] = headlines\n",
        "\n",
        "    all_headlines = news_dict\n",
        "    return news_dict\n",
        "\n",
        "def analyze_single_ticker_sentiment(ticker_symbol):\n",
        "    if ticker_symbol not in all_headlines:\n",
        "        fetch_company_news([ticker_symbol])\n",
        "\n",
        "    headlines = all_headlines.get(ticker_symbol, [\"No recent news found.\"])\n",
        "\n",
        "    if headlines == [\"No recent news found.\"]:\n",
        "        return \"No recent news available.\", \"\"\n",
        "\n",
        "    sentiment_counts = {\"positive\": 0, \"neutral\": 0, \"negative\": 0}\n",
        "    results = pipe(headlines)\n",
        "\n",
        "    output_lines = []\n",
        "    for i, (headline, result) in enumerate(zip(headlines, results), 1):\n",
        "        label = result[\"label\"].lower()\n",
        "        sentiment_counts[label] += 1\n",
        "        output_lines.append(f\"**{i}. {headline}**\\n   ➤ Sentiment: {result['label']} (Confidence: {round(result['score'], 3)})\")\n",
        "\n",
        "    total = sum(sentiment_counts.values())\n",
        "    overall = max(sentiment_counts, key=sentiment_counts.get)\n",
        "\n",
        "    summary = f\"📊 **Overall Sentiment for {ticker_symbol}: {overall.upper()}**\\n\"\n",
        "    summary += f\"Positive: {sentiment_counts['positive']}  |  Neutral: {sentiment_counts['neutral']}  |  Negative: {sentiment_counts['negative']}\"\n",
        "\n",
        "    return \"\\n\\n\".join(output_lines), summary\n",
        "\n",
        "# Gradio UI\n",
        "with gr.Blocks() as app:\n",
        "    gr.Markdown(\"# 📰 Stock News Sentiment Analysis with FinBERT\")\n",
        "\n",
        "    with gr.Row():\n",
        "        ticker_input = gr.Dropdown(choices=ticker_list, label=\"Select a Stock Ticker\")\n",
        "        analyze_button = gr.Button(\"Analyze\")\n",
        "\n",
        "    sentiment_output = gr.Textbox(label=\"News Headlines & Sentiments\", lines=15)\n",
        "    summary_output = gr.Textbox(label=\"Overall Sentiment Summary\")\n",
        "\n",
        "    analyze_button.click(\n",
        "        fn=analyze_single_ticker_sentiment,\n",
        "        inputs=[ticker_input],\n",
        "        outputs=[sentiment_output, summary_output]\n",
        "    )\n",
        "\n",
        "# Launch the app\n",
        "app.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFXrtoLS-7ZZ",
        "outputId": "f553dd7b-be1d-45a0-c5e5-c508f48caf09"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AAPL: -13.50%\n",
            "MSFT: 6.17%\n",
            "GOOGL: -13.55%\n",
            "AMZN: -20.70%\n",
            "TSLA: -25.21%\n",
            "META: -14.70%\n",
            "NVDA: -8.21%\n",
            "BRK-B: 8.99%\n",
            "JPM: -5.49%\n",
            "V: 0.40%\n",
            "PG: -5.47%\n",
            "JNJ: 1.26%\n",
            "UNH: -24.03%\n",
            "HD: -11.54%\n",
            "MA: -0.39%\n",
            "DIS: -15.89%\n",
            "PYPL: -13.01%\n",
            "NFLX: 12.85%\n",
            "INTC: 3.87%\n",
            "PEP: -8.25%\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "\n",
        "# List of tickers\n",
        "ticker_list = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"META\", \"NVDA\", \"BRK-B\", \"JPM\", \"V\",\n",
        "    \"PG\", \"JNJ\", \"UNH\", \"HD\", \"MA\", \"DIS\", \"PYPL\", \"NFLX\", \"INTC\", \"PEP\"\n",
        "]\n",
        "\n",
        "def fetch_profit_loss(tickers, period='1y'):\n",
        "    \"\"\"\n",
        "    Fetches profit or loss percentage for a list of stock tickers over a given period.\n",
        "\n",
        "    Args:\n",
        "    tickers (list): List of stock ticker symbols (e.g., ['AAPL', 'MSFT', 'AMZN']).\n",
        "    period (str): Time period for calculating profit/loss ('1d', '5d', '1mo', '3mo', '1y').\n",
        "\n",
        "    Returns:\n",
        "    dict: A dictionary with tickers as keys and profit/loss percentages as values.\n",
        "    \"\"\"\n",
        "    profit_loss_dict = {}\n",
        "\n",
        "    for ticker_symbol in tickers:\n",
        "        ticker = yf.Ticker(ticker_symbol)\n",
        "\n",
        "        # Get historical market data for the desired period\n",
        "        hist_data = ticker.history(period=period)\n",
        "\n",
        "        # Get the opening price from the start of the period and the current closing price\n",
        "        start_price = hist_data['Close'].iloc[0]\n",
        "        end_price = hist_data['Close'].iloc[-1]\n",
        "\n",
        "        # Calculate the percentage change (Profit or Loss)\n",
        "        profit_loss_percentage = ((end_price - start_price) / start_price) * 100\n",
        "        profit_loss_dict[ticker_symbol] = profit_loss_percentage\n",
        "\n",
        "    return profit_loss_dict\n",
        "\n",
        "# Fetch profit/loss for all companies in the ticker list over 1 year\n",
        "profit_loss_percentage = fetch_profit_loss(ticker_list, period='3mo')\n",
        "\n",
        "# Print the profit/loss percentage for each company\n",
        "for ticker, pl_percentage in profit_loss_percentage.items():\n",
        "    print(f\"{ticker}: {pl_percentage:.2f}%\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "id": "ZSnTDnkEbmjA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0709634d-01f2-4218-e50f-76ea931e8fac"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               EBITDA Margin (%)\n",
            "AAPL                   31.029059\n",
            "MSFT                   45.671224\n",
            "GOOGL                  33.918479\n",
            "AMZN                   11.823315\n",
            "TSLA                     2.54978\n",
            "META                   41.487451\n",
            "NVDA                   61.107015\n",
            "BRK-B  Error: 'Operating Income'\n",
            "JPM    Error: 'Operating Income'\n",
            "V                      67.073171\n",
            "PG                     23.048139\n",
            "JNJ                    28.771754\n",
            "UNH                     7.710774\n",
            "HD                     11.321277\n",
            "MA                     59.324138\n",
            "DIS                    16.516808\n",
            "PYPL                   20.485175\n",
            "NFLX                   31.746772\n",
            "INTC                   -1.144707\n",
            "PEP                    14.414867\n"
          ]
        }
      ],
      "source": [
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "ticker_list = [\n",
        "    \"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"META\", \"NVDA\", \"BRK-B\", \"JPM\", \"V\",\n",
        "    \"PG\", \"JNJ\", \"UNH\", \"HD\", \"MA\", \"DIS\", \"PYPL\", \"NFLX\", \"INTC\", \"PEP\"\n",
        "]\n",
        "\n",
        "ebitda_margins = {}\n",
        "\n",
        "for ticker_symbol in ticker_list:\n",
        "    ticker = yf.Ticker(ticker_symbol)\n",
        "\n",
        "    try:\n",
        "        financials = ticker.quarterly_financials\n",
        "\n",
        "        # Extract revenue and operating income\n",
        "        revenue = financials.loc['Total Revenue']\n",
        "        operating_income = financials.loc['Operating Income']\n",
        "\n",
        "        # Handle depreciation safely\n",
        "        if 'Depreciation' in financials.index:\n",
        "            depreciation_amortization = financials.loc['Depreciation']\n",
        "        else:\n",
        "            # If missing, assume 0 (safe fallback)\n",
        "            depreciation_amortization = pd.Series(0, index=revenue.index)\n",
        "\n",
        "        # Calculate EBITDA and Margin\n",
        "        ebitda = operating_income + depreciation_amortization\n",
        "        ebitda_margin = (ebitda / revenue) * 100\n",
        "\n",
        "        # Store latest margin\n",
        "        ebitda_margins[ticker_symbol] = ebitda_margin.iloc[0]\n",
        "\n",
        "    except Exception as e:\n",
        "        ebitda_margins[ticker_symbol] = f\"Error: {e}\"\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame.from_dict(ebitda_margins, orient='index', columns=['EBITDA Margin (%)'])\n",
        "print(df)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "id": "kh2R91dKbmmk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "7f903b8d-53a9-4ed5-fd94-29eb55a2ee89"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://03c0e253bb3943c691.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://03c0e253bb3943c691.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Load FinBERT sentiment pipeline\n",
        "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
        "\n",
        "# Mapping of full company names to tickers\n",
        "company_dict = {\n",
        "    \"Apple Inc.\": \"AAPL\",\n",
        "    \"Microsoft Corporation\": \"MSFT\",\n",
        "    \"Alphabet Inc. (Google)\": \"GOOGL\",\n",
        "    \"Amazon.com, Inc.\": \"AMZN\",\n",
        "    \"Tesla, Inc.\": \"TSLA\",\n",
        "    \"Meta Platforms, Inc.\": \"META\",\n",
        "    \"NVIDIA Corporation\": \"NVDA\",\n",
        "    \"Berkshire Hathaway Inc.\": \"BRK-B\",\n",
        "    \"JPMorgan Chase & Co.\": \"JPM\",\n",
        "    \"Visa Inc.\": \"V\",\n",
        "    \"Procter & Gamble Co.\": \"PG\",\n",
        "    \"Johnson & Johnson\": \"JNJ\",\n",
        "    \"UnitedHealth Group Incorporated\": \"UNH\",\n",
        "    \"The Home Depot, Inc.\": \"HD\",\n",
        "    \"Mastercard Incorporated\": \"MA\",\n",
        "    \"The Walt Disney Company\": \"DIS\",\n",
        "    \"PayPal Holdings, Inc.\": \"PYPL\",\n",
        "    \"Netflix, Inc.\": \"NFLX\",\n",
        "    \"Intel Corporation\": \"INTC\",\n",
        "    \"PepsiCo, Inc.\": \"PEP\"\n",
        "}\n",
        "\n",
        "# Fetch news headlines for a ticker\n",
        "def fetch_news(ticker_symbol):\n",
        "    ticker = yf.Ticker(ticker_symbol)\n",
        "    news_data = ticker.news\n",
        "    return [article.get(\"title\", \"\") for article in news_data] if news_data else []\n",
        "\n",
        "# Analyze sentiment of headlines\n",
        "def analyze_sentiment(headlines):\n",
        "    sentiment_counts = {\"positive\": 0, \"neutral\": 0, \"negative\": 0}\n",
        "    if headlines:\n",
        "        results = pipe(headlines)\n",
        "        for result in results:\n",
        "            label = result[\"label\"].lower()\n",
        "            sentiment_counts[label] += 1\n",
        "        overall_sentiment = max(sentiment_counts, key=sentiment_counts.get).upper()\n",
        "    else:\n",
        "        overall_sentiment = \"NO DATA\"\n",
        "    return sentiment_counts, overall_sentiment\n",
        "\n",
        "# Calculate profit/loss\n",
        "def fetch_profit_loss(ticker, period='3mo'):\n",
        "    hist_data = yf.Ticker(ticker).history(period=period)\n",
        "    if hist_data.empty:\n",
        "        return None\n",
        "    start_price = hist_data['Close'].iloc[0]\n",
        "    end_price = hist_data['Close'].iloc[-1]\n",
        "    return ((end_price - start_price) / start_price) * 100\n",
        "\n",
        "# Calculate EBITDA Margin (latest quarter)\n",
        "def fetch_ebitda_margin(ticker_symbol):\n",
        "    try:\n",
        "        ticker = yf.Ticker(ticker_symbol)\n",
        "        financials = ticker.quarterly_financials\n",
        "\n",
        "        revenue = financials.loc['Total Revenue']\n",
        "        operating_income = financials.loc['Operating Income']\n",
        "\n",
        "        if 'Depreciation' in financials.index:\n",
        "            depreciation_amortization = financials.loc['Depreciation']\n",
        "        else:\n",
        "            depreciation_amortization = pd.Series(0, index=revenue.index)\n",
        "\n",
        "        ebitda = operating_income + depreciation_amortization\n",
        "        ebitda_margin = (ebitda / revenue) * 100\n",
        "        return ebitda_margin.iloc[0]\n",
        "\n",
        "    except Exception as e:\n",
        "        return None\n",
        "\n",
        "# Combined Gradio function\n",
        "def analyze_company(company_name):\n",
        "    ticker = company_dict[company_name]\n",
        "    headlines = fetch_news(ticker)\n",
        "    sentiment_counts, overall_sentiment = analyze_sentiment(headlines)\n",
        "    profit_loss = fetch_profit_loss(ticker)\n",
        "    ebitda_margin = fetch_ebitda_margin(ticker)\n",
        "\n",
        "    sentiment_output = (\n",
        "        f\"📰 **Sentiment Analysis for {company_name} ({ticker})**\\n\"\n",
        "        f\"Positive: {sentiment_counts['positive']}\\n\"\n",
        "        f\"Neutral: {sentiment_counts['neutral']}\\n\"\n",
        "        f\"Negative: {sentiment_counts['negative']}\\n\"\n",
        "        f\"Overall: {overall_sentiment}\\n\"\n",
        "    )\n",
        "\n",
        "    pl_output = (\n",
        "        f\"\\n💹 **Profit/Loss for last 3 months**: \"\n",
        "        f\"{profit_loss:.2f}%\" if profit_loss is not None else \"\\n💹 No price data available.\"\n",
        "    )\n",
        "\n",
        "    ebitda_output = (\n",
        "        f\"\\n📈 **Latest EBITDA Margin**: {ebitda_margin:.2f}%\" if ebitda_margin is not None else \"\\n📈 EBITDA margin not available.\"\n",
        "    )\n",
        "\n",
        "    news_output = \"\\n\\n🗞 **Top News Headlines:**\\n\" + \"\\n\".join([f\"- {h}\" for h in headlines[:5]]) if headlines else \"\\n\\n🗞 No recent headlines found.\"\n",
        "\n",
        "    return sentiment_output + pl_output + ebitda_output + news_output\n",
        "\n",
        "# Gradio app\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 📊 Company Market Sentiment & Financial Performance Tracker\")\n",
        "    company_dropdown = gr.Dropdown(\n",
        "        choices=list(company_dict.keys()),\n",
        "        label=\"Select a Company\",\n",
        "        interactive=True\n",
        "    )\n",
        "    output_box = gr.Textbox(label=\"Analysis Output\", lines=20, interactive=False)\n",
        "    company_dropdown.change(fn=analyze_company, inputs=company_dropdown, outputs=output_box)\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "E8pW9kR3eAL2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "outputId": "5d0f60fd-44e7-4e90-84db-f3b4f63962f0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://b8d68b755904c0d7eb.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b8d68b755904c0d7eb.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 39
        }
      ],
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# Load FinBERT sentiment pipeline\n",
        "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
        "\n",
        "# Mapping of full company names to tickers\n",
        "company_dict = {\n",
        "    \"Apple Inc.\": \"AAPL\",\n",
        "    \"Microsoft Corporation\": \"MSFT\",\n",
        "    \"Alphabet Inc. (Google)\": \"GOOGL\",\n",
        "    \"Amazon.com, Inc.\": \"AMZN\",\n",
        "    \"Tesla, Inc.\": \"TSLA\",\n",
        "    \"Meta Platforms, Inc.\": \"META\",\n",
        "    \"NVIDIA Corporation\": \"NVDA\",\n",
        "    \"Berkshire Hathaway Inc.\": \"BRK-B\",\n",
        "    \"JPMorgan Chase & Co.\": \"JPM\",\n",
        "    \"Visa Inc.\": \"V\",\n",
        "    \"Procter & Gamble Co.\": \"PG\",\n",
        "    \"Johnson & Johnson\": \"JNJ\",\n",
        "    \"UnitedHealth Group Incorporated\": \"UNH\",\n",
        "    \"The Home Depot, Inc.\": \"HD\",\n",
        "    \"Mastercard Incorporated\": \"MA\",\n",
        "    \"The Walt Disney Company\": \"DIS\",\n",
        "    \"PayPal Holdings, Inc.\": \"PYPL\",\n",
        "    \"Netflix, Inc.\": \"NFLX\",\n",
        "    \"Intel Corporation\": \"INTC\",\n",
        "    \"PepsiCo, Inc.\": \"PEP\"\n",
        "}\n",
        "\n",
        "# Fetch news headlines for a ticker\n",
        "def fetch_news(ticker_symbol):\n",
        "    ticker = yf.Ticker(ticker_symbol)\n",
        "    news_data = ticker.news\n",
        "    return [article.get(\"title\", \"\") for article in news_data] if news_data else []\n",
        "\n",
        "# Analyze sentiment of headlines\n",
        "def analyze_sentiment(headlines):\n",
        "    sentiment_counts = {\"positive\": 0, \"neutral\": 0, \"negative\": 0}\n",
        "    if headlines:\n",
        "        results = pipe(headlines)\n",
        "        for result in results:\n",
        "            label = result[\"label\"].lower()\n",
        "            sentiment_counts[label] += 1\n",
        "        overall_sentiment = max(sentiment_counts, key=sentiment_counts.get).upper()\n",
        "    else:\n",
        "        overall_sentiment = \"NO DATA\"\n",
        "    return sentiment_counts, overall_sentiment\n",
        "\n",
        "# Calculate profit/loss\n",
        "def fetch_profit_loss(ticker, period='3mo'):\n",
        "    hist_data = yf.Ticker(ticker).history(period=period)\n",
        "    if hist_data.empty:\n",
        "        return None\n",
        "    start_price = hist_data['Close'].iloc[0]\n",
        "    end_price = hist_data['Close'].iloc[-1]\n",
        "    return ((end_price - start_price) / start_price) * 100\n",
        "\n",
        "# Calculate EBITDA Margin\n",
        "def fetch_ebitda_margin(ticker_symbol):\n",
        "    try:\n",
        "        ticker = yf.Ticker(ticker_symbol)\n",
        "        financials = ticker.quarterly_financials\n",
        "\n",
        "        revenue = financials.loc['Total Revenue']\n",
        "        operating_income = financials.loc['Operating Income']\n",
        "\n",
        "        if 'Depreciation' in financials.index:\n",
        "            depreciation_amortization = financials.loc['Depreciation']\n",
        "        else:\n",
        "            depreciation_amortization = pd.Series(0, index=revenue.index)\n",
        "\n",
        "        ebitda = operating_income + depreciation_amortization\n",
        "        ebitda_margin = (ebitda / revenue) * 100\n",
        "        return ebitda_margin.iloc[0]\n",
        "    except:\n",
        "        return None\n",
        "\n",
        "# Calculate ROI and ROE\n",
        "def fetch_roi_roe(ticker_symbol):\n",
        "    try:\n",
        "        ticker = yf.Ticker(ticker_symbol)\n",
        "        financials = ticker.quarterly_financials\n",
        "        balance_sheet = ticker.quarterly_balance_sheet\n",
        "\n",
        "        net_income = financials.loc['Net Income']\n",
        "        total_assets = balance_sheet.loc['Total Assets']\n",
        "        total_equity = balance_sheet.loc[\"Total Stockholder Equity\"]\n",
        "\n",
        "        roi = (net_income / total_assets * 100).iloc[0]\n",
        "        roe = (net_income / total_equity * 100).iloc[0]\n",
        "\n",
        "        return roi, roe\n",
        "    except:\n",
        "        return None, None\n",
        "\n",
        "# Combined Gradio function\n",
        "def analyze_company(company_name):\n",
        "    ticker = company_dict[company_name]\n",
        "    headlines = fetch_news(ticker)\n",
        "    sentiment_counts, overall_sentiment = analyze_sentiment(headlines)\n",
        "    profit_loss = fetch_profit_loss(ticker)\n",
        "    ebitda_margin = fetch_ebitda_margin(ticker)\n",
        "    roi, roe = fetch_roi_roe(ticker)\n",
        "\n",
        "    sentiment_output = (\n",
        "        f\"📰 **Sentiment Analysis for {company_name} ({ticker})**\\n\"\n",
        "        f\"Positive: {sentiment_counts['positive']}\\n\"\n",
        "        f\"Neutral: {sentiment_counts['neutral']}\\n\"\n",
        "        f\"Negative: {sentiment_counts['negative']}\\n\"\n",
        "        f\"Overall: {overall_sentiment}\\n\"\n",
        "    )\n",
        "\n",
        "    pl_output = (\n",
        "        f\"\\n💹 **Profit/Loss for last 3 months**: \"\n",
        "        f\"{profit_loss:.2f}%\" if profit_loss is not None else \"\\n💹 No price data available.\"\n",
        "    )\n",
        "\n",
        "    ebitda_output = (\n",
        "        f\"\\n📈 **Latest EBITDA Margin**: {ebitda_margin:.2f}%\" if ebitda_margin is not None else \"\\n📈 EBITDA margin not available.\"\n",
        "    )\n",
        "\n",
        "    roi_output = (\n",
        "        f\"\\n💰 **Return on Investment (ROI)**: {roi:.2f}%\" if roi is not None else \"\\n💰 ROI not available.\"\n",
        "    )\n",
        "\n",
        "    roe_output = (\n",
        "        f\"\\n🏦 **Return on Equity (ROE)**: {roe:.2f}%\" if roe is not None else \"\\n🏦 ROE not available.\"\n",
        "    )\n",
        "\n",
        "    news_output = \"\\n\\n🗞 **Top News Headlines:**\\n\" + \"\\n\".join([f\"- {h}\" for h in headlines[:5]]) if headlines else \"\\n\\n🗞 No recent headlines found.\"\n",
        "\n",
        "    return sentiment_output + pl_output + ebitda_output + roi_output + roe_output + news_output\n",
        "\n",
        "# Gradio app\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 📊 Company Market Sentiment & Financial Metrics Dashboard\")\n",
        "    company_dropdown = gr.Dropdown(\n",
        "        choices=list(company_dict.keys()),\n",
        "        label=\"Select a Company\",\n",
        "        interactive=True\n",
        "    )\n",
        "    output_box = gr.Textbox(label=\"Analysis Output\", lines=25, interactive=False)\n",
        "    company_dropdown.change(fn=analyze_company, inputs=company_dropdown, outputs=output_box)\n",
        "\n",
        "demo.launch()\n"
      ]
    },
    {
      "source": [
        "import gradio as gr\n",
        "from transformers import pipeline\n",
        "import yfinance as yf\n",
        "import pandas as pd\n",
        "\n",
        "# ... (rest of your existing code) ...\n",
        "\n",
        "# Gradio app\n",
        "with gr.Blocks() as demo:\n",
        "    gr.Markdown(\"## 📊 Company Market Sentiment & Financial Metrics Dashboard\")\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 📰 **Sentiment Analysis**\")\n",
        "            company_dropdown = gr.Dropdown(\n",
        "                choices=list(company_dict.keys()),\n",
        "                label=\"Select a Company for Sentiment\",\n",
        "                interactive=True\n",
        "            )\n",
        "            sentiment_output = gr.Textbox(label=\"Sentiment Analysis Output\", lines=15, interactive=False)\n",
        "            company_dropdown.change(fn=lambda x: analyze_company(x)[0], inputs=company_dropdown, outputs=sentiment_output)\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 📊 **Financial Metrics**\")\n",
        "            financial_output = gr.Textbox(label=\"Financial Metrics Output\", lines=25, interactive=False)\n",
        "            company_dropdown.change(fn=lambda x: analyze_company(x)[1], inputs=company_dropdown, outputs=financial_output)\n",
        "\n",
        "    with gr.Row():\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 🗞 **Latest News Headlines**\")\n",
        "            news_output = gr.Textbox(label=\"News Output\", lines=10, interactive=False)\n",
        "            company_dropdown.change(fn=lambda x: analyze_company(x)[2], inputs=company_dropdown, outputs=news_output)\n",
        "\n",
        "        with gr.Column():\n",
        "            gr.Markdown(\"### 🧠 **Investment Advice**\")\n",
        "            advice_output = gr.Textbox(label=\"Buy/Sell Recommendation\", lines=3, interactive=False)\n",
        "            company_dropdown.change(fn=lambda x: analyze_company(x)[3], inputs=company_dropdown, outputs=advice_output)\n",
        "        # Removed the st.markdown lines as they were causing the error and st was not imported\n",
        "        # If you intended to use st (streamlit), make sure it is installed and imported\n",
        "        # and that the indentation is correct.\n",
        "\n",
        "    demo.launch()"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "nTTNyKUDHU2B",
        "outputId": "9667f70f-a753-4fce-a453-33437712b4f5"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://996d384c6de6a77124.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://996d384c6de6a77124.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}